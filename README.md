# AICI Challenge 1 & 2 â€” Perceptra Solution

## Overview
This repository contains the implementation and outputs for **Challenge 1** and **Challenge 2** of the AICI Computer Vision & Robotics Assessment.  

- **Challenge 1:** Detect and localize indoor furniture (chair, couch, table, shelf, bathtub, WC) on a **2D occupancy grid map** using RGB survey data.  
- **Challenge 2:** Concatenate and **colorize LiDAR point clouds** using synchronized RGB camera data to produce a **single colored 3D point cloud (PLY)** representing the full surveyed environment.

---

## ðŸ“¦ Folder Structure

```
Perceptra/
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ detect_and_overlay_v2.py       # Challenge 1
â”‚   â”œâ”€â”€ list_bag_topics.py             # Utility to inspect ROS bag topics
â”‚   â””â”€â”€ colorize_and_merge_fixed.py    # Challenge 2 (final robust version)
â”‚
â”œâ”€â”€ results/
â”‚   â””â”€â”€ office/
â”‚       â”œâ”€â”€ detections.json            # Challenge 1: object poses & sizes
â”‚       â”œâ”€â”€ map_with_detections.png    # Challenge 1: overlay on occupancy grid
â”‚       â””â”€â”€ office_colored.ply         # Challenge 2: merged colored point cloud
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ office/
â”‚       â”œâ”€â”€ room.pgm                   # Occupancy map
â”‚       â”œâ”€â”€ room.yaml                  # Map metadata (resolution, origin)
â”‚       â””â”€â”€ frames/                    # RGB frames extracted from ROS bag
â”‚
â””â”€â”€ Perceptra.ipynb                    # Notebook used for testing in Google Colab
```

---

## ðŸš€ Challenge 1 â€” Object Detection & Projection

### Script
`detect_and_overlay_v2.py`

Runs YOLOv8 object detection on RGB frames and projects detections into **map coordinates** (meters).  
Generates oriented bounding boxes and stores full detection metadata.

### Usage
```bash
python scripts/detect_and_overlay_v2.py   --room-yaml data/office/room.yaml   --room-pgm  data/office/room.pgm   --rgb-dir   data/office/frames   --out-dir   results/office   --model yolov8n.pt   --only-best-frame
```

### Output
- `detections.json` â†’ Object metadata (class, pose, size)  
- `map_with_detections.png` â†’ Visual overlay of detections on occupancy map  

---

## ðŸš€ Challenge 2 â€” Point Cloud Concatenation & Colorization

### Script
`colorize_and_merge_fixed.py`

This script merges LiDAR and RGB camera data into a single **colored point cloud** by:
1. Reading LiDAR and camera messages from ROS2 bags (`rosbags` library).  
2. Using TF transforms for spatial alignment.  
3. Projecting camera colors onto LiDAR points.  
4. Downsampling to manage memory (optimized for Colab).  

### Example (Colab command used)
```bash
python scripts/colorize_and_merge_fixed.py   --bags "/content/drive/MyDrive/Perceptra/bags/office_survey_1"   --cloud-topic "/livox/lidar"   --image-topic "/zed/zed_node/rgb/image_rect_color/compressed"   --caminfo-topic "/zed/zed_node/rgb/camera_info"   --tf-topics /tf /tf_static   --world-frame livox_frame   --sync-tol 0.5   --stride 6   --max-clouds 600   --percloud-voxel 0.08   --voxel 0.15   --out results/office/office_colored.ply
```

### Output
- `office_colored.ply` â†’ Merged, colorized 3D point cloud of the environment  
  (fully viewable in **Open3D**, **CloudCompare**, or **MeshLab**)  

---

## ðŸ§° Dependencies
Install via pip:
```bash
pip install rosbags open3d==0.18.0 opencv-python-headless numpy pyyaml tqdm ultralytics
```

---

## âœ… Compliance Checklist

| Requirement | Challenge 1 | Challenge 2 |
|--------------|-------------|-------------|
| Non-overlapping bounding boxes | âœ… | â€” |
| â‰¥ 2 object classes detected | âœ… | â€” |
| Map-aligned detections (meters) | âœ… | â€” |
| Pose & dimension metadata | âœ… | â€” |
| Oriented bounding boxes | âœ… | â€” |
| Merged point cloud (PLY) | â€” | âœ… |
| Colorized using RGB images | â€” | âœ… |
| TF synchronization | â€” | âœ… |
| Reproducible CLI script | âœ… | âœ… |

---

## ðŸ§© Summary
This solution fully completes **Challenge 1** and **Challenge 2** of the AICI Robotics assessment:  
- **Challenge 1:** map-aligned detections, JSON + visual overlays  
- **Challenge 2:** robust colored point-cloud generation with per-cloud voxel downsampling (Colab-optimized)  

Both stages are reproducible via command-line or Colab Notebook and ready for final submission.
